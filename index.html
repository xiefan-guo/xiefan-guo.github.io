<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xiefan Guo's Homepage</title>
    <link href="https://fonts.googleapis.com/css2?family=Cormorant:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&family=Cardo:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;0,700;1,400&family=EB+Garamond:wght@400;500;600&display=swap" rel="stylesheet"> -->
   
    <style>
        /* 优雅学术字体组合 */
        body {
            font-family: 'Times New Roman', 'Cardo', Georgia, Times, 'Cormorant Garamond', 'Cardo', Georgia, serif;
            font-weight: 400;
            font-size: 16px;
            line-height: 1.6;
            /* color: #333; */
            color: black;
            max-width: 1050px;
            margin: 0 auto;
            padding: 50px 40px;
            /* background-color: #fcfaf7; */
            text-rendering: optimizeLegibility;
            -webkit-font-smoothing: antialiased;
        }
     
        h1, h2, h3, h4 {
            font-family: 'Times New Roman', 'Cardo', 'Cormorant', Garamond, serif;
            font-weight: 500;
            margin: 0;
            color: #222;
            letter-spacing: 0.4px;
        }
     
        h1 {
            font-size: 2rem;
            margin-bottom: 15px;
            position: relative;
            display: inline-block;
            font-weight: 600;
            letter-spacing: 0.8px;
        }
     
        h1:after {
            content: "";
            position: absolute;
            bottom: -10px;
            left: 0;
            width: 100%;
            height: 2px;
            /* background: linear-gradient(90deg, #8d6e63, #c0b3a8, #8d6e63); */
            /* background: linear-gradient(90deg, rgba(6, 69, 173, 0.2), rgba(6, 69, 173, 0.2), rgba(6, 69, 173, 0.2)); */
            background: linear-gradient(90deg, black, black, black);
            opacity: 0.7;
        }
     
        h2 {
            font-size: 1.5rem;
            margin: 0px 0 0px;
            padding-bottom: 1rem;
            /* border-bottom: 2px solid #d7ccc8; */
            font-weight: 600;
            letter-spacing: 0.6px;
        }
       
        h3 {
            font-size: 1.25rem;
            margin: 0px 0 0px;
            color: #444;
            font-weight: 500;
            font-style: italic;
            letter-spacing: 0.5px;
        }
     
        .position {
            font-size: 1.25rem;
            color: #666;
            margin-bottom: 28px;
            font-style: italic;
            font-weight: 600;
            letter-spacing: 0.6px;
            font-family: 'Cormorant', serif;
        }
     
        .contact {
            font-size: 1rem;
            color: #666;
            margin: 32px 0;
            line-height: 1.85;
            padding-left: 24px;
            /* border-left: 3px solid #d7ccc8; */
            border-left: 3px solid rgba(6, 69, 173, 0.2);
            /* font-variant: small-caps; */
            letter-spacing: 0.8px;
        }
     
        section {
            margin-bottom: 3rem;
        }
     
        p {
            margin: 0 0 1rem 0;
            text-align: left;
            letter-spacing: 0.2px;
        }
     
        ul {
            padding-left: 2rem;
            margin: 0 0 1rem 0;
            /* list-style-type: square; */
        }
     
        li {
            /* margin-bottom: 18px; */
            position: relative;
            line-height: 1.6;
        }

        .experience {
            margin-left: 0.5rem;
            margin-bottom: 0px;
            padding: 0 0 0 24px;
            /* border-left: 2px solid #e0d6c9; */
            border-left: 2px solid rgba(6, 69, 173, 0.2);
        }

        .publication {
            margin-left: 0.5rem;
            margin-bottom: 0px;
            padding: 0 0 0 22px;
            /* border-left: 2px solid #e0d6c9; */
            /* border-left: 2px solid rgba(6, 69, 173, 0.2); */
            border-left: 2px solid rgba(0, 0, 0, 1);
        }
     
        .date {
            font-style: italic;
            color: #777;
            font-size: 1.12rem;
            display: block;
            margin-top: 8px;
            letter-spacing: 0.4px;
        }
     
        footer {
            text-align: center;
            margin-top: 90px;
            padding-top: 48px;
            border-top: 1px solid #d7ccc8;
            font-size: 1.08rem;
            color: #777;
            font-family: 'Cormorant', serif;
            letter-spacing: 0.8px;
        }
     
        a {
            /* color: #5d4037; */
            color: #0645AD;
            text-decoration: none;
            /* transition: all 0.35s ease; */
            /* border-bottom: 1px solid rgba(93, 64, 55, 0.3); */
            /* padding-bottom: 1px; */
        }
     
        /* a:hover {
            color: #3e2723;
            border-bottom: 1px solid rgba(62, 39, 35, 0.7);
        } */
     
        .content {
            padding: 0 35px;
        }
     
        .institution {
            font-style: italic;
            color: #5d4037;
            font-weight: 600;
            font-variant: normal;
        }
     
        /* .publication em {
            font-style: normal;
            color: #5d4037;
            font-weight: 600;
        } */
     
        .highlight {
            position: relative;
            font-weight: 500;
            padding: 0 2px;
            /* background: linear-gradient(180deg, rgba(255,255,255,0) 70%, rgba(141, 110, 99, 0.2) 65%); */
            background: linear-gradient(180deg, rgba(255,255,255,0) 75%, rgba(6, 69, 173, 0.1) 65%);
            /* background: linear-gradient(180deg, rgba(255,255,255,0) 75%, rgba(0, 0, 0, 0.1) 65%); */
            font-style: italic;
        }
     
        .name-decoration {
            position: relative;
            display: inline-block;
            padding-bottom: 0px;
        }
     
        /* 响应式设计 */
        @media (max-width: 850px) {
            body {
                padding: 45px 30px;
                max-width: 95%;
            }
            h1 {
                font-size: 2.8rem;
            }
            h2 {
                font-size: 1.85rem;
            }
        }
     
        @media (max-width: 600px) {
            body {
                padding: 38px 22px;
            }
            h1 {
                font-size: 2.5rem;
            }
            h2 {
                font-size: 1.7rem;
                margin: 60px 0 35px;
            }
            .contact {
                padding-left: 22px;
                font-variant: normal;
            }
        }
     
        @media (max-width: 480px) {
            body {
                padding: 32px 18px;
            }
            h1 {
                font-size: 2.2rem;
            }
            .position {
                font-size: 1.3rem;
            }
            .content {
                padding: 0 25px;
            }
        }
     
        /* 打印优化 */
        @media print {
            body {
                background: white;
                padding: 20px;
                max-width: 100%;
                font-size: 12pt;
            }
            a {
                border: none;
            }
            .highlight {
                background: none;
                font-weight: bold;
                font-style: normal;
            }
        }
     
        /* 优雅的装饰元素 */
        .ornament {
            text-align: center;
            margin: 45px 0;
            color: #8d6e63;
            opacity: 0.4;
            font-size: 1.5rem;
            letter-spacing: 8px;
        }
    </style>
</head>
<body>
    <div class="content">
        <header>
            <h1 style="line-height: 1.25;"><span class="name-decoration">Xiefan Guo</span></h1>
            <p class="position">Ph.D. Student @ Beihang University (BUAA)</p>
            <!-- <p class="institution">Institute for Advanced Study, Princeton</p> -->
            <p class="contact">
                Email: <a href="mailto:guoxiefan@gmail.com">guoxiefan@gmail.com</a> <br>
                <!-- Office: <br> -->
                <!-- Phone: <br> -->
                [<a href="https://scholar.google.com/citations?user=X4MKw-wAAAAJ&hl=en">Google Scholar</a>]
                [<a href="https://github.com/xiefan-guo">Github</a>]
                [<a href="https://dblp.uni-trier.de/pid/249/0970.html">DBLP</a>]
                [<a href="https://twitter.com/guoxiefan">Twitter</a>]
            </p>
        </header>
     
        <section id="about">
            <!-- <h2>About</h2> -->
            <p>
                I am a Ph.D. student at the School of Computer Science and Engineering, <a href="https://www.buaa.edu.cn/">Beihang University</a> (BUAA),
                supervised by Prof. <a href="https://irip.buaa.edu.cn/dihuang/index.html">Di Huang</a>.
                My research interests focus on <span class="highlight">Computer Vision</span>, <span class="highlight">Generative AI</span>, and <span class="highlight">Diffusion models</span>.
            </p>
            <p>
                Before that, I received my master degree from the School of Computer Science and Engineering, <a href="https://www.buaa.edu.cn/">Beihang University</a> (BUAA), China, in Jan. 2023
                and B.E degree from the College of Intelligence and Computing, <a href="https://www.tju.edu.cn/">Tianjin University</a> (TJU), China, in Jul. 2020.
                I interned at <a href="">Shanghai AI Laboratory</a>, <a href="https://tongyi.aliyun.com/">Alibaba TongYi Lab</a> and <a href="https://damo.alibaba.com/">Alibaba DAMO Academy</a>.
            </p>
           
        </section>
     
        <!-- <section id="research">
            <h2>Research Interests</h2>
            <ul>
                <li>Quantum gravity and holographic duality</li>
                <li>Entanglement structure in quantum field theories</li>
                <li>Quantum information dynamics in black hole physics</li>
                <li>Emergent spacetime from quantum entanglement</li>
                <li>Tensor networks as models of holography</li>
                <li>Quantum complexity and chaos in gravitational systems</li>
            </ul>
        </section> -->

        <section id="news">
            <h2>News <a href="./news/index.html" rel="external nofollow noopener" target="_blank"><font style="font-size: 16px;">[more]</font></a></h2>
            <ul>
                <li><font class="highlight">2025.06:</font> Our paper, titled “<font style="font-variant: small-caps;">ShortFT</font>: Diffusion Model Alignment via Shortcut-based Fine-Tuning” is accepted by <a href="https://iccv.thecvf.com/">ICCV 2025</a>.</li>
                <!-- <li>2025.04: I start my intern at Shanghai AI Laboratory.</li> -->
                <li><font class="highlight">2025.02:</font> Our paper, titled “Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent Diffusion Models” is accepted by <a href="https://cvpr2025.thecvf.com/">CVPR 2025</a>.</li>
               
                <!-- <li>2024.06: We release the official PyTorch implementation of <a href="https://github.com/xiefan-guo/i4vgen">I4VGen</a>.</li>
                <li>2024.05: Invited talk at Alibaba Cloud on <a href="https://arxiv.org/abs/2404.04650">InitNO</a>, CVPR 2024.</li>
                <li>2024.02: Our paper, titled “<font style="font-variant: small-caps;">InitNO</font>: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization” is accepted by <a href="https://cvpr2024.thecvf.com/">CVPR 2024</a>.</li>
                <li>2024.02: Our paper, titled “Leveraging Predicate and Triplet Learning for Scene Graph Generation” is accepted by <a href="https://cvpr2024.thecvf.com/">CVPR 2024</a>.</li>
                <li>2023.09: I start my intern at Alibaba TongYi Lab.</li>
                <li>2022.03: Our paper, titled “ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo” is accepted by <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.</li>
                <li>2021.09: I obtain China National Scholarship.</li>
                <li>2021.07: Our paper, titled “Image Inpainting via Conditional Texture and Structure Dual Generation” is accepted by <a href="https://iccv2021.thecvf.com/">ICCV 2021</a>.</li> -->
            </ul>
        </section>
       

        <section id="publications">
            <h2>Selected Publications</h2>
            <p>See the full list on my <a href="https://scholar.google.com/citations?user=X4MKw-wAAAAJ&hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a>.</p>
            <!-- <h3>Preprints</h3> -->

            <div class="publication">
                <p>
                    <b><font style="font-variant: small-caps;">ShortFT</font>: Diffusion Model Alignment via Shortcut-based Fine-Tuning</b> <br>
                    <b>Xiefan Guo</b>, Miaomiao Cui, Liefeng Bo, and Di Huang <br>
                    In: <em>The 20th IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), Oct. 19-23, 2025, Hawaii, USA <br>
                    [<a href="">Paper</a>]
                    [<a href="">Code</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b>Ultra-High-Resolution Image Synthesis: Data, Method and Evaluation</b> <br>
                    Jinjin Zhang, Qiuyu Huang, Junjie Liu, <b>Xiefan Guo</b>, and Di Huang <br>
                    In: <em>arXiv:2506.01331</em>, Technical Report, 2025 <br>
                    [<a href="https://arxiv.org/abs/2506.01331">Paper</a>]
                    [<a href="https://github.com/zhang0jhon/diffusion-4k">Code</a>]
                    [<a href="https://huggingface.co/datasets/zhang0jhon/Aesthetic-Train-V2">Dataset</a>]
                </p>
            </div>
           
            <div class="publication">
                <p>
                    <b>Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent Diffusion Models</b> <br>
                    Jinjin Zhang, Qiuyu Huang, Junjie Liu, <b>Xiefan Guo</b>, and Di Huang <br>
                    In: <em>The 43nd IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), Jun. 11-15, 2025, Nashville, USA <br>
                    [<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Diffusion-4K_Ultra-High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models_CVPR_2025_paper.html">Paper</a>]
                    [<a href="https://arxiv.org/abs/2503.18352">arXiv</a>]
                    [<a href="https://github.com/zhang0jhon/diffusion-4k">Code</a>]
                    [<a href="https://huggingface.co/datasets/zhang0jhon/Aesthetic-4K">Dataset</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b><font style="font-variant: small-caps;">I4VGen</font>: Image as Free Stepping Stone for Text-to-Video Generation</b> <br>
                    <b>Xiefan Guo</b>, Jinlin Liu, Miaomiao Cui, Liefeng Bo, and Di Huang <br>
                    In: <em>arXiv:2406.02230</em>, Technical Report, 2024 <br>
                    [<a href="https://arxiv.org/abs/2406.02230">Paper</a>]
                    [<a href="https://github.com/xiefan-guo/i4vgen">Code</a>]
                    [<a href="https://xiefan-guo.github.io/i4vgen/">Project</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b><font style="font-variant: small-caps;">InitNO</font>: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization</b> <br>
                    <b>Xiefan Guo</b>, Jinlin Liu, Miaomiao Cui, Jiankai Li, Hongyu Yang, and Di Huang <br>
                    In: <em>The 42nd IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), Jun. 17-21, 2024, Seattle, USA <br>
                    [<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Guo_InitNO_Boosting_Text-to-Image_Diffusion_Models_via_Initial_Noise_Optimization_CVPR_2024_paper.html">Paper</a>]
                    [<a href="https://arxiv.org/abs/2404.04650">arXiv</a>]
                    [<a href="https://github.com/xiefan-guo/initno">Code</a>]
                    [<a href="https://xiefan-guo.github.io/initno/">Project</a>]
                    [<a href="https://drive.google.com/file/d/14HfV0YYvT5P2glY5DjTEgY8Fc6WS8ThR/view">Slide</a>]
                    [<a href="https://drive.google.com/file/d/1epc_4LUmYba0yYzB3pXcTZuXIcuQEpim/view">Poster</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b>Leveraging Predicate and Triplet Learning for Scene Graph Generation</b> <br>
                    Jiankai Li, Yunhong Wang, <b>Xiefan Guo</b>, Ruijie Yang, and Weixin Li <br>
                    In: <em>The 42nd IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), Jun. 17-21, 2024, Seattle, USA <br>
                    [<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Leveraging_Predicate_and_Triplet_Learning_for_Scene_Graph_Generation_CVPR_2024_paper.html">Paper</a>]
                    [<a href="https://arxiv.org/abs/2406.02038">arXiv</a>]
                    [<a href="https://github.com/jkli1998/DRM">Code</a>]
                </p>
            </div>
           
            <!-- <div class="publication">
                <p>
                    <b>Disentangling Foreground and Background Motion for Enhanced Realism in Human Video Generation</b> <br>
                    Jinlin Liu, Kai Yu, Mengyang Feng, <b>Xiefan Guo</b>, and Miaomiao Cui <br>
                    In: <em>arXiv:2405.16393</em>, Technical Report, 2024 <br>
                    [<a href="https://arxiv.org/abs/2405.16393">Paper</a>]
                    [<a href="https://liujl09.github.io/humanvideo_movingbackground/">Project</a>]
                </p>
            </div> -->

            <div class="publication">
                <p>
                    <b>DreaMoving: A Human Video Generation Framework based on Diffusion Models</b> <br>
                    DreaMoving Team: Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, <b><b>Xiefan Guo</b></b>, Xianhui Lin, <em>et al.</em> <br>
                    In: <em>arXiv:2312.05107</em>, Technical Report, 2023 <br>
                    [<a href="https://arxiv.org/abs/2312.05107">Paper</a>]
                    [<a href="https://github.com/dreamoving/dreamoving-project">Code</a>]
                    [<a href="https://dreamoving.github.io/dreamoving/">Project</a>]
                    [<a href="https://www.modelscope.cn/studios/vigen/video_generation/summary">ModelScope</a>]
                    [<a href="https://huggingface.co/spaces/jiayong/Dreamoving">Hugging Face</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b>ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo</b> <br>
                    Biwen Lei, <b>Xiefan Guo</b>, Hongyu Yang, Miaomiao Cui, Xuansong Xie, and Di Huang <br>
                    In: <em>The 40th IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), Jun. 19-24, 2022, New Orleans, USA <br>
                    [<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.html">Paper</a>]
                    [<a href="https://modelscope.cn/models/damo/cv_unet_skin-retouching/summary">ModelScope</a>]
                    [<a href="https://github.com/youngLBW/CRHD-3K">Dataset</a>]
                </p>
            </div>

            <div class="publication">
                <p>
                    <b>Image Inpainting via Conditional Texture and Structure Dual Generation</b> <br>
                    <b>Xiefan Guo</b>, Hongyu Yang, and Di Huang <br>
                    In: <em>The 18th IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), Oct. 11-17, 2021, Montreal, Canada (Virtual) <br>
                    [<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Guo_Image_Inpainting_via_Conditional_Texture_and_Structure_Dual_Generation_ICCV_2021_paper.html">Paper</a>]
                    [<a href="https://arxiv.org/abs/2108.09760">arXiv</a>]
                    [<a href="https://github.com/xiefan-guo/ctsdg">Code</a>]
                    [<a href="https://drive.google.com/file/d/1HLPMJQHWC1Ac4GHnnXaRdh6ZGadjwAcL/view">Slide</a>]
                    [<a href="https://drive.google.com/file/d/1WN0jqh5zkc-_tiXKYx1kMI2OZPWIVx8s/view">Poster</a>]
                </p>
            </div>

        </section>
     

        <section id="honors">
            <h2>Honors</h2>
            <ul>
                <li>2023: Outstanding Freshman Scholarship for PhD Student, Beihang University</li>
                <li>2022: Excellent Graduate Award, Beihang University</li>
                <li>2022: Tansuo Award, Beihang University</li>
                <li>2021: National Scholarship, Beihang University</li>
                <li>2020: Excellent Graduate Award, Tianjin University</li>
                <li>2019: National Scholarship, Tianjin University</li>
                <li>2018: Silver Medal, ACM International Collegiate Programming Contest (ACM-ICPC), Asia Regional Contest</li>
                <li>2018: Silver Medal, China Collegiate Programming Contest (CCPC), Regional Contest</li>
                <li>2018: Weichai Power Scholarship, Tianjin University</li>
            </ul>
        </section>
     

        <section id="activities">
            <h2>Professional Activities</h2>
            <ul>
                <li style="line-height: 1.75"><b>Conference Reviewer:</b> CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, AISTATS, ACM MM, ICMR, ECAI, BMVC, PRCV</li>
                <li style="line-height: 1.75"><b>Journal Reviewer:</b> TPAMI, TVCG, TCSVT, TMM, CVIU, FCS, J-STSP</li>
            </ul>
        </section>
   
    </div>
 
    <!-- <footer>
        <p>Xiefan Guo | Beihang University</p>
        <p>Beijing | Last updated: June 21, 2025</p>
    </footer> -->
</body>
</html>
